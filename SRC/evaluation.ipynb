{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d4ef50fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "from nltk.stem import PorterStemmer\n",
    "from collections import Counter \n",
    "from tqdm import tqdm\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "00e5b950",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\",\\\n",
    "            \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', \\\n",
    "            'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their',\\\n",
    "            'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', \\\n",
    "            'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', \\\n",
    "            'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', \\\n",
    "            'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after',\\\n",
    "            'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further',\\\n",
    "            'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more',\\\n",
    "            'most', 'other', 'some', 'such', 'only', 'own', 'same', 'so', 'than', 'too', 'very', \\\n",
    "            's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', \\\n",
    "            've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn',\\\n",
    "            \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn',\\\n",
    "            \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", \\\n",
    "            'won', \"won't\", 'wouldn', \"wouldn't\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9ced830c",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_stemmer = PorterStemmer()\n",
    "lemmatizer = WordNetLemmatizer ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "33bbd73c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decontracted(phrase):\n",
    "    # specific\n",
    "    phrase = re.sub(r\"won't\", \"will not\", phrase)      # replace won't with \"will not\"\n",
    "    phrase = re.sub(r\"can\\'t\", \"can not\", phrase)      # replace can or cant with 'can not'\n",
    "    phrase = re.sub(r\"n\\'t\", \" not\", phrase)           # replece n with 'not'\n",
    "    phrase = re.sub(r\"\\'re\", \" are\", phrase)           # replace re with 'are'\n",
    "    phrase = re.sub(r\"\\'s\", \" is\", phrase)             # replace s with 'is'\n",
    "    phrase = re.sub(r\"\\'d\", \" would\", phrase)          # replace 'd' with 'would'\n",
    "    phrase = re.sub(r\"\\'ll\", \" will\", phrase)          # replace 'll with 'will'\n",
    "    phrase = re.sub(r\"\\'t\", \" not\", phrase)            # replace 't' with 'not'\n",
    "    phrase = re.sub(r\"\\'ve\", \" have\", phrase)          # replace ve with 'have'\n",
    "    phrase = re.sub(r\"\\'m\", \" am\", phrase)             # replace 'm with 'am'\n",
    "    return phrase\n",
    "\n",
    "  \n",
    "def preprocess_text(text_data):\n",
    "    preprocessed_text = []             \n",
    "    # tqdm is for printing the status bar\n",
    "    for sentance in tqdm(text_data):\n",
    "        sent = decontracted(sentance)           #calling funcion for each sentence\n",
    "        #print(\"1st sent\" , sent)\n",
    "        sent = sent.replace('\\\\r', ' ')         # replace line terminator with space\n",
    "        sent = sent.replace('\\\\n', ' ')         # replace new line charactor with space\n",
    "        sent = sent.replace('\\\\\"', ' ')         \n",
    "        sent = re.sub('[^A-Za-z]+', ' ', sent)  # remove anything that is not letter\n",
    "        sent = ''.join(p_stemmer.stem(token) for token in sent )\n",
    "        sent = ''.join(lemmatizer.lemmatize(token) for token in sent )\n",
    "        sent  = ' '.join(e for e in sent.split() if len( Counter(e)) > 2 )\n",
    "        #sent = lstr(emmatize_text(sent)\n",
    "        \n",
    "        sent = ' '.join(e for e in sent.split() if e.lower() not in 'root/nltk_data/corpora/stop_words') # checking for stop words\n",
    "        preprocessed_text.append(sent.lower().strip())\n",
    "    return preprocessed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1343777c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../Dataset/test - test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "76d31f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "data =df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "62ee6ba4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 1003.18it/s]\n"
     ]
    }
   ],
   "source": [
    "g=preprocess_text([df['text'][5]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "9d52b7af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['love the but missing some features likes keeping backlog tasks']"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "eb50d5aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:01<00:00, 636.99it/s]\n"
     ]
    }
   ],
   "source": [
    "data['text']=preprocess_text(data['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d319cdd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X1 = data['text']\n",
    "X2 = data['aspect']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a897f9cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../Models/best_lrc.pickle\", 'rb') as data:\n",
    "    lrc = pickle.load(data)\n",
    "with open(\"../Data Engineering/PickleFiles/tfidf1.pickle\", 'rb') as data:\n",
    "    tfidf1 = pickle.load(data)\n",
    "with open(\"../Data Engineering/PickleFiles/tfidf2.pickle\", 'rb') as data:\n",
    "    tfidf2 = pickle.load(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "0a76bab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_test_tfidf1 = tfidf1.transform(g).toarray()\n",
    "#features_test_tfidf2 = tfidf2.transform(X2).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "147e7b07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 3991)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_test_tfidf1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a1b2016a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 3991)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_test_tfidf1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "517ede64",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.concatenate((features_test_tfidf1, features_test_tfidf2), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e8512837",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 4887)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "62c92347",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_label = lrc.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "d5e5a4b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data1=df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "888b3960",
   "metadata": {},
   "outputs": [],
   "source": [
    "data1['label']=y_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "bdf2ef69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>aspect</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>improve your customer service and product avai...</td>\n",
       "      <td>Customer service</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>functionality is great, almost as in desktop v...</td>\n",
       "      <td>mobile version</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>but it keeps starting from zoomed in and then ...</td>\n",
       "      <td>zoomed</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hey marilyn thanks for your answer the soc2 ty...</td>\n",
       "      <td>Security</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@delanovc @zoom @airtable @notionhq @calendly ...</td>\n",
       "      <td>apple</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text            aspect  label\n",
       "0  improve your customer service and product avai...  Customer service      0\n",
       "1  functionality is great, almost as in desktop v...    mobile version      0\n",
       "2  but it keeps starting from zoomed in and then ...            zoomed      0\n",
       "3  hey marilyn thanks for your answer the soc2 ty...          Security      1\n",
       "4  @delanovc @zoom @airtable @notionhq @calendly ...             apple      1"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "261e7d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "data1.to_csv(r'../data/results/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c24c08e4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
